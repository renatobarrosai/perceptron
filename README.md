# üß† Implementa√ß√£o de Rede Neural Perceptron

<div align="center">

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)

![Status](https://img.shields.io/badge/Status-Conclu√≠do-success?style=flat-square)
![Licen√ßa](https://img.shields.io/badge/Licen√ßa-MIT-blue?style=flat-square)
![Python Version](https://img.shields.io/badge/Python-3.7+-brightgreen?style=flat-square)

*Uma implementa√ß√£o educacional de Perceptron em Python puro para compreender os fundamentos das redes neurais artificiais*

</div>

---

## üìã Sum√°rio

- [üéØ Sobre o Projeto](#-sobre-o-projeto)
- [üîß Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [üìä Resultados Obtidos](#-resultados-obtidos)
- [üöÄ Como Executar](#-como-executar)
- [üìñ Conceitos Fundamentais](#-conceitos-fundamentais)
- [üìà Processo de Treinamento](#-processo-de-treinamento)
- [üßÆ F√≥rmulas Matem√°ticas](#-f√≥rmulas-matem√°ticas)
- [üìÅ Estrutura do Projeto](#-estrutura-do-projeto)
- [üéì Aprendizados](#-aprendizados)
- [üë• Contribui√ß√£o](#-contribui√ß√£o)
- [üìÑ Licen√ßa](#-licen√ßa)

---

## üéØ Sobre o Projeto

Este projeto implementa um **Perceptron** do zero em Python, sem o uso de bibliotecas externas de machine learning, com o objetivo de solidificar o entendimento sobre redes neurais artificiais e algoritmos de aprendizado de m√°quina.

### ‚ú® Caracter√≠sticas Principais

- üî¨ **Implementa√ß√£o Pura**: C√≥digo Python sem depend√™ncias externas
- üìö **Fins Educacionais**: Explica√ß√µes detalhadas de cada conceito
- üìä **Visualiza√ß√£o Detalhada**: Acompanhamento do processo de treinamento √©poca por √©poca
- üéØ **Converg√™ncia Garantida**: Modelo converge para erro zero em dados linearmente separ√°veis

### üè¢ Aplica√ß√µes Pr√°ticas

O Perceptron pode ser aplicado em diversos cen√°rios corporativos:

- üõí **E-commerce**: Previs√£o de produtos com potencial de viraliza√ß√£o
- üë• **Marketing**: Identifica√ß√£o de potenciais compradores
- üîç **Recomenda√ß√£o**: Classifica√ß√£o de prefer√™ncias de usu√°rios
- üì¶ **Log√≠stica**: Previs√£o de tempos de entrega
- üîê **Seguran√ßa**: Detec√ß√£o de atividades fraudulentas

---

## üîß Tecnologias Utilizadas

| Tecnologia | Vers√£o | Uso |
|------------|--------|-----|
| ![Python](https://img.shields.io/badge/Python-3.7+-blue) | 3.7+ | Linguagem principal |
| ![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange) | Latest | Ambiente de desenvolvimento |
| ![Markdown](https://img.shields.io/badge/Markdown-000000) | - | Documenta√ß√£o |

---

## üìä Resultados Obtidos

### üèÜ M√©tricas de Performance

| M√©trica | Valor |
|---------|-------|
| **√âpocas at√© Converg√™ncia** | 12 |
| **Taxa de Aprendizagem** | 0.1 |
| **Erro Final** | 0 (Zero) |
| **Peso Final W1** | 0.23 |
| **Peso Final W2** | -0.14 |

### üìà Evolu√ß√£o do Treinamento

```
√âpoca  1: Erros = 1  | W1 = 0.20, W2 = -0.10
√âpoca  2: Erros = 2  | W1 = 0.18, W2 = -0.14
...
√âpoca 12: Erros = 0  | W1 = 0.23, W2 = -0.14 ‚úÖ CONVERGIU!
```

> üéØ **Sucesso**: O modelo convergiu com **erro zero** na **12¬™ √©poca**, demonstrando efic√°cia na classifica√ß√£o dos dados linearmente separ√°veis.

---

## üöÄ Como Executar

### üìã Pr√©-requisitos

```bash
# Verificar vers√£o do Python
python --version  # Python 3.7+

# Instalar Jupyter (opcional)
pip install jupyter
```

### ‚ñ∂Ô∏è Executando o Projeto

1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/seu-usuario/perceptron-implementation.git
   cd perceptron-implementation
   ```

2. **Execute o notebook**
   ```bash
   jupyter notebook perceptron.ipynb
   ```

3. **Ou abra diretamente no Jupyter Lab**
   ```bash
   jupyter lab perceptron.ipynb
   ```

---

## üìñ Conceitos Fundamentais

### üßÆ O que √© um Perceptron?

O **Perceptron** √© a forma mais simples de uma rede neural artificial, inspirado no funcionamento dos neur√¥nios biol√≥gicos. Ele processa informa√ß√µes atrav√©s de tr√™s etapas principais:

```mermaid
graph LR
    A[Entradas x1, x2] --> B[Soma Ponderada]
    B --> C[Fun√ß√£o de Ativa√ß√£o]
    C --> D[Sa√≠da y]
    E[Pesos w1, w2] --> B
```

### üîÑ Processo de Funcionamento

| Etapa | Descri√ß√£o | F√≥rmula |
|-------|-----------|---------|
| **1. Combina√ß√£o Linear** | Multiplica entradas pelos pesos | `u = (x1 √ó w1) + (x2 √ó w2)` |
| **2. Fun√ß√£o de Ativa√ß√£o** | Aplica fun√ß√£o degrau | `y = 1 se u ‚â• 0, sen√£o 0` |
| **3. Ajuste de Pesos** | Corrige erros usando regra delta | `w_novo = w_atual + Œ∑ √ó erro √ó x` |

---

## üìà Processo de Treinamento

### üéØ Dados de Treinamento

```python
dados_treinamento = [
    {"x1": 0.5, "x2": 0.8, "saida_desejada": 1},  # Classe positiva
    {"x1": 0.2, "x2": 0.4, "saida_desejada": 0},  # Classe negativa
]
```

### ‚öôÔ∏è Par√¢metros do Modelo

| Par√¢metro | Valor | Descri√ß√£o |
|-----------|-------|-----------|
| **Pesos Iniciais** | `[0.2, -0.1]` | Valores aleat√≥rios iniciais |
| **Taxa de Aprendizagem** | `0.1` | Controla velocidade de ajuste |
| **Limite de √âpocas** | `20` | M√°ximo de itera√ß√µes |

### üîÑ Algoritmo de Treinamento

```python
for epoca in range(limite_epocas):
    erro_na_epoca = False
    for dado in dados_treinamento:
        # 1. Calcular sa√≠da
        u = x1 * w1 + x2 * w2
        saida = 1 if u >= 0 else 0
        
        # 2. Calcular erro
        erro = saida_desejada - saida
        
        # 3. Ajustar pesos (se necess√°rio)
        if erro != 0:
            w1 += taxa_aprendizagem * erro * x1
            w2 += taxa_aprendizagem * erro * x2
            erro_na_epoca = True
    
    # 4. Verificar converg√™ncia
    if not erro_na_epoca:
        print(f"Convergiu na √©poca {epoca}!")
        break
```

---

## üßÆ F√≥rmulas Matem√°ticas

### üìê Combina√ß√£o Linear
```
u = Œ£(xi √ó wi) = x1√ów1 + x2√ów2
```

### üîÄ Fun√ß√£o de Ativa√ß√£o (Degrau)
```
f(u) = {
    1, se u ‚â• 0
    0, se u < 0
}
```

### üìä Regra Delta (Ajuste de Pesos)
```
wi(novo) = wi(atual) + Œ∑ √ó erro √ó xi
```

**Onde:**
- `Œ∑` (eta) = taxa de aprendizagem
- `erro` = sa√≠da_desejada - sa√≠da_predita
- `xi` = valor da entrada i

---

## üìÅ Estrutura do Projeto

```
perceptron-implementation/
‚îÇ
‚îú‚îÄ‚îÄ üìì perceptron.ipynb          # Notebook principal com implementa√ß√£o completa
‚îî‚îÄ‚îÄ üìÑ README.md                 # Este arquivo com documenta√ß√£o do projeto
```

### üìã Descri√ß√£o dos Arquivos

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `perceptron.ipynb` | Jupyter Notebook contendo toda a implementa√ß√£o do Perceptron, explica√ß√µes te√≥ricas detalhadas e resultados do treinamento |
| `README.md` | Documenta√ß√£o principal do projeto com vis√£o geral, instru√ß√µes e conceitos fundamentais |

---

## üéì Aprendizados

### ‚úÖ O que Funciona Bem

- ‚úîÔ∏è **Dados Linearmente Separ√°veis**: Perceptron garante converg√™ncia
- ‚úîÔ∏è **Implementa√ß√£o Simples**: C√≥digo limpo e compreens√≠vel
- ‚úîÔ∏è **Interpretabilidade**: Pesos finais t√™m significado claro

### ‚ö†Ô∏è Limita√ß√µes Identificadas

- ‚ùå **Dados N√£o-Lineares**: N√£o consegue classificar (ex: XOR)
- ‚ùå **Apenas Bin√°rio**: Limitado a classifica√ß√£o de duas classes
- ‚ùå **Sensibilidade**: Performance depende dos pesos iniciais

### üß† Insights dos Pesos Finais

| Peso | Valor | Interpreta√ß√£o |
|------|-------|---------------|
| **W1** | `+0.23` | Influ√™ncia **positiva** - aumenta probabilidade de classe 1 |
| **W2** | `-0.14` | Influ√™ncia **negativa** - diminui probabilidade de classe 1 |

---

## üë• Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. üç¥ **Fork** o projeto
2. üåø Crie uma **branch** para sua feature (`git checkout -b feature/AmazingFeature`)
3. üìù **Commit** suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. üì§ **Push** para a branch (`git push origin feature/AmazingFeature`)
5. üîÑ Abra um **Pull Request**

### üí° Ideias para Contribui√ß√£o

- [ ] üìä Adicionar visualiza√ß√µes gr√°ficas do treinamento
- [ ] üß™ Implementar outros tipos de fun√ß√£o de ativa√ß√£o
- [ ] üìà Criar m√©tricas de avalia√ß√£o mais detalhadas
- [ ] üéØ Adicionar mais exemplos de dados de treinamento
- [ ] üìö Expandir documenta√ß√£o te√≥rica

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT.

---

<div align="center">

### üåü Se este projeto foi √∫til, considere dar uma estrela!

**Desenvolvido por [Renato Barros]**

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/seu-usuario)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/seu-perfil)

*"A jornada de mil quil√¥metros come√ßa com um √∫nico passo."* - Lao Tzu

</div>
